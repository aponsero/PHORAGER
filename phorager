#!/usr/bin/env python3

import os
import re
import sys
import shutil
import argparse
import logging
import subprocess
from datetime import datetime
from pathlib import Path
import multiprocessing

class TerminalColors:
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    RED = '\033[91m'
    RESET = '\033[0m'

class NextflowConfigParser:
    @staticmethod
    def _resolve_project_dir():
        """
        Resolve the project directory based on the current script location
        """
        return os.path.dirname(os.path.abspath(sys.argv[0]))

    @staticmethod
    def parse_config(config_path='nextflow.config'):
        """
        Parse Nextflow configuration file to extract specific parameters
        """
        # Resolve project directory
        project_dir = NextflowConfigParser._resolve_project_dir()

        try:
            with open(config_path, 'r') as f:
                config_content = f.read()
        except FileNotFoundError:
            raise FileNotFoundError(f"Nextflow config file not found: {config_path}")

        # Replace $projectDir with the actual project directory path
        config_content = config_content.replace('$projectDir', project_dir)

        # Existing parsing methods...

        return {
            'db_location': NextflowConfigParser.parse_db_location(config_content),
            'conda_cache_dir': NextflowConfigParser.parse_conda_cache(config_content),
            'genome': NextflowConfigParser.parse_genome(config_content),
            'threads': NextflowConfigParser._parse_threads(config_content),
            'completeness_threshold': NextflowConfigParser.parse_completeness_threshold(config_content),
            'contamination_threshold': NextflowConfigParser.parse_contamination_threshold(config_content),
            'drep_ani_threshold': NextflowConfigParser.parse_drep_ani_threshold(config_content),
            'outdir': NextflowConfigParser._parse_outdir(config_content),
            'use_dereplicated_genomes': NextflowConfigParser._parse_use_dereplicated_genomes(config_content),
            'run_genomad': NextflowConfigParser._parse_run_genomad(config_content),
            'run_vibrant': NextflowConfigParser._parse_run_vibrant(config_content),
            'genomad_db_location': NextflowConfigParser._parse_db_location_for_tool(config_content, 'genomad'),
            'vibrant_db_location': NextflowConfigParser._parse_db_location_for_tool(config_content, 'vibrant')
        }

    @staticmethod
    def _parse_threads(config_content):
        """
        Parse default threads from config content
        Defaults to number of available CPU cores if not specified
        """
        try:
            threads_match = re.search(r'threads\s*=\s*Runtime\.runtime\.availableProcessors\(\)', config_content)
            if threads_match:
                return multiprocessing.cpu_count()
            
            # Alternative parsing if explicit number is used
            threads_num_match = re.search(r'threads\s*=\s*(\d+)', config_content)
            if threads_num_match:
                return int(threads_num_match.group(1))
            
            # Default to all available cores if no specification found
            return multiprocessing.cpu_count()
        except Exception:
            # Fallback to all available cores
            return multiprocessing.cpu_count()

    @staticmethod
    def parse_db_location(config_content):
        """
        Parse global database location from config content
        """
        db_match = re.search(r'global_db_location\s*=\s*"([^"]+)"', config_content)
        db_location = db_match.group(1) if db_match else None

        if not db_location:
            raise ValueError("Could not parse database location from config")

        return os.path.expandvars(os.path.expanduser(db_location))

    @staticmethod
    def parse_conda_cache(config_content):
        """
        Parse conda cache directory from config content
        """
        cache_match = re.search(r'conda_cache_dir\s*=\s*"([^"]+)"', config_content)
        conda_cache_dir = cache_match.group(1) if cache_match else None

        if not conda_cache_dir:
            raise ValueError("Could not parse conda cache directory from config")

        return os.path.expandvars(os.path.expanduser(conda_cache_dir))

    @staticmethod
    def parse_genome(config_content):
        """
        Parse genome location from config content
        """
        genome_match = re.search(r'genome\s*=\s*"([^"]+)"', config_content)
        genome = genome_match.group(1) if genome_match else None

        if not genome:
            raise ValueError("Could not parse genome location from config")

        return os.path.expandvars(os.path.expanduser(genome))

    @staticmethod
    def parse_completeness_threshold(config_content):
        """
        Parse completeness threshold from config content
        """
        threshold_match = re.search(r'completeness_threshold\s*=\s*(\d+\.?\d*)', config_content)
        threshold = float(threshold_match.group(1)) if threshold_match else 95.0

        return threshold

    @staticmethod
    def parse_contamination_threshold(config_content):
        """
        Parse contamination threshold from config content
        """
        threshold_match = re.search(r'contamination_threshold\s*=\s*(\d+\.?\d*)', config_content)
        threshold = float(threshold_match.group(1)) if threshold_match else 5.0

        return threshold

    @staticmethod
    def parse_drep_ani_threshold(config_content):
        """
        Parse dRep ANI threshold from config content
        """
        threshold_match = re.search(r'drep_ani_threshold\s*=\s*(\d+\.?\d*)', config_content)
        threshold = float(threshold_match.group(1)) if threshold_match else 0.999

        return threshold

    @staticmethod
    def _parse_outdir(config_content):
        """
        Parse output directory from config content
        """
        outdir_match = re.search(r'outdir\s*=\s*"([^"]+)"', config_content)
        outdir = outdir_match.group(1) if outdir_match else "$projectDir/results"
        
        # Expand project directory and user home
        outdir = os.path.expandvars(os.path.expanduser(outdir))
        
        return outdir
    
    @staticmethod
    def _parse_use_dereplicated_genomes(config_content):
        """
        Parse use_dereplicated_genomes parameter
        """
        match = re.search(r'use_dereplicated_genomes\s*=\s*(\w+)', config_content)
        return match.group(1).lower() == 'true' if match else False

    @staticmethod
    def _parse_run_genomad(config_content):
        """
        Parse run_genomad parameter
        """
        match = re.search(r'run_genomad\s*=\s*(\w+)', config_content)
        print("MATCH:", match)
        if match:
            result = match.group(1).lower() == 'true'
            print("RESULT:", result)
            return result
        return True  # Default to True if not specified

    @staticmethod
    def _parse_run_vibrant(config_content):
        """
        Parse run_vibrant parameter
        """
        match = re.search(r'run_vibrant\s*=\s*(\w+)', config_content)
        print("MATCH:", match)
        if match:
            result = match.group(1).lower() == 'true'
            print("RESULT:", result)
            return result
        return True  # Default to True if not specified

    @staticmethod
    def _parse_db_location_for_tool(config_content, tool):
        """
        Parse database location for a specific tool
        """
        match = re.search(rf'{tool}_db_location\s*=\s*"([^"]+)"', config_content)
        db_location = match.group(1) if match else None
        
        if not db_location:
            raise ValueError(f"Could not parse {tool} database location from config")
        
        return os.path.expandvars(os.path.expanduser(db_location))

class PhoragerInstaller:
    def __init__(self, 
                 db_location=None, 
                 conda_cache_dir=None, 
                 force_reinstall=False, 
                 verbose=False):
        # Parse configuration
        config = NextflowConfigParser.parse_config()
        
        # Override config with CLI arguments if provided
        self.db_location = os.path.expandvars(os.path.expanduser(db_location)) if db_location else config['db_location']
        self.conda_cache_dir = os.path.expandvars(os.path.expanduser(conda_cache_dir)) if conda_cache_dir else config['conda_cache_dir']
        
        self.force_reinstall = force_reinstall
        self.verbose = verbose
        
        # Logging setup
        self._setup_logging()
    
    def _setup_logging(self):
        """
        Configure logging with file and console output
        """
        # Create logs directory if it doesn't exist
        log_dir = Path('./phorager_logs')
        log_dir.mkdir(exist_ok=True)
        
        # Generate log filename with timestamp
        log_filename = log_dir / f"install_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        
        # Configure logging
        logging.basicConfig(
            level=logging.DEBUG if self.verbose else logging.INFO,
            format='%(asctime)s - %(levelname)s: %(message)s',
            handlers=[
                logging.FileHandler(log_filename),
                logging.StreamHandler(sys.stdout)
            ]
        )
        self.logger = logging.getLogger(__name__)
        
        # Log the locations being used
        self.logger.info(f"Database Location: {self.db_location}")
        self.logger.info(f"Conda Cache Directory: {self.conda_cache_dir}")
    
    def _validate_nextflow_installation(self):
        """
        Check if Nextflow is installed and accessible
        """
        try:
            subprocess.run(['nextflow', '-version'], 
                           stdout=subprocess.PIPE, 
                           stderr=subprocess.PIPE, 
                           check=True)
        except (subprocess.CalledProcessError, FileNotFoundError):
            self.logger.error(f"{TerminalColors.RED}Nextflow is not installed or not in PATH.{TerminalColors.RESET}")
            sys.exit(1)
    
    def _check_disk_space(self, locations, min_space_gb=100):
        """
        Check available disk space for multiple locations
        """
        for location in locations:
            try:
                total, used, free = shutil.disk_usage(location)
                free_gb = free / (1024**3)
                
                if free_gb < min_space_gb:
                    self.logger.error(
                        f"{TerminalColors.RED}Insufficient disk space for {location}. "
                        f"Required: {min_space_gb}G, Available: {free_gb:.2f}G{TerminalColors.RESET}"
                    )
                    sys.exit(1)
            except Exception as e:
                self.logger.warning(f"Could not check disk space for {location}: {e}")
    
    def _prepare_directories(self):
        """
        Create database and conda cache directories if they don't exist
        """
        for location in [self.db_location, self.conda_cache_dir]:
            os.makedirs(location, exist_ok=True)
            self.logger.info(f"Ensuring directory exists: {location}")

    
        """
        Run Nextflow installation workflow with optional verbose output
        """
        # Installation command
        install_cmd = [
            'nextflow', 
            'run', 
            'main.nf', 
            '-profile', 'conda',
            '--workflow', 'install',
            f'--global_db_location', self.db_location,
            f'--conda_cache_dir', self.conda_cache_dir
        ]
        
        # Add force flag if specified
        if self.force_reinstall:
            install_cmd.append('--force')
        
        try:
            # Run installation with explicit output handling
            self.logger.info(f"{TerminalColors.YELLOW}Starting database installation...{TerminalColors.RESET}")
            
            # Use subprocess with explicit output control
            if self.verbose:
                # If verbose, use subprocess.run to show all output
                install_result = subprocess.run(
                    install_cmd, 
                    check=True,
                    text=True
                )
            else:
                # If not verbose, capture output for error analysis
                install_result = subprocess.run(
                    install_cmd, 
                    capture_output=True,
                    text=True,
                    check=True
                )
            
        except subprocess.CalledProcessError as e:
            # Log full error details
            self.logger.error(
                f"{TerminalColors.RED}Installation failed:{TerminalColors.RESET}"
            )
            # Print stderr to help diagnose the issue
            if e.stderr:
                self.logger.error(f"Error output: {e.stderr}")
            if e.stdout:
                self.logger.error(f"Standard output: {e.stdout}")
            
            # If in verbose mode, also print to console
            if self.verbose:
                print(f"Error output: {e.stderr}")
                print(f"Standard output: {e.stdout}")
            
            sys.exit(1)

    def _run_nextflow_install(self):
        """
        Run Nextflow installation workflow with comprehensive logging
        """
        # Installation command
        install_cmd = [
            'nextflow', 
            'run', 
            'main.nf', 
            '-profile', 'conda',
            '--workflow', 'install',
            f'--global_db_location', self.db_location,
            f'--conda_cache_dir', self.conda_cache_dir
        ]
        
        # Add force flag if specified
        if self.force_reinstall:
            install_cmd.append('--force')
        
        try:
            # Run installation with comprehensive output handling
            self.logger.info(f"{TerminalColors.YELLOW}Starting database installation...{TerminalColors.RESET}")
            
            # Use subprocess.Popen for real-time output capture
            install_process = subprocess.Popen(
                install_cmd, 
                stdout=subprocess.PIPE, 
                stderr=subprocess.STDOUT, 
                text=True,
                bufsize=1,
                universal_newlines=True
            )
            
            # Capture all output
            output_lines = []
            while True:
                output = install_process.stdout.readline()
                if output == '' and install_process.poll() is not None:
                    break
                if output:
                    output = output.strip()
                    output_lines.append(output)
                    
                    # Log all output
                    self.logger.info(output)
                    
                    # Print to console if verbose
                    if self.verbose:
                        print(output)
            
            # Check process return code
            if install_process.returncode != 0:
                # Log full output if installation failed
                for line in output_lines:
                    self.logger.error(f"Installation Error: {line}")
                raise subprocess.CalledProcessError(
                    install_process.returncode, 
                    install_cmd, 
                    '\n'.join(output_lines)
                )
            
            # Log and print installation success
            success_message = f"{TerminalColors.GREEN}Database installation successful!{TerminalColors.RESET}"
            self.logger.info(success_message)
            print(success_message)
            
            # Clean and remove work directory
            clean_cmd = ['nextflow', 'clean', '-f']
            try:
                # Remove Nextflow cache
                subprocess.run(clean_cmd, check=True, capture_output=not self.verbose, text=True)
                
                # Remove work directory
                work_dir = os.path.join(self._resolve_project_dir(), 'work')
                if os.path.exists(work_dir):
                    shutil.rmtree(work_dir)
                    
                    # Log and print work directory removal
                    rm_message = f"{TerminalColors.GREEN}Nextflow work directory removed successfully!{TerminalColors.RESET}"
                    self.logger.info(rm_message)
                    print(rm_message)
                
            except Exception as clean_error:
                # Log cleanup error
                error_message = f"{TerminalColors.YELLOW}Failed to clean directories: {clean_error}{TerminalColors.RESET}"
                self.logger.warning(error_message)
                print(error_message)
        
        except subprocess.CalledProcessError as e:
            error_message = f"{TerminalColors.RED}Installation failed: {e}{TerminalColors.RESET}"
            self.logger.error(error_message)
            print(error_message)
            sys.exit(1)

    def _resolve_project_dir(self):
        """
        Resolve the project directory based on the current script location
        """
        return os.path.dirname(os.path.abspath(sys.argv[0]))

    def run(self):
            """
            Main installation workflow
            """
            # Validate Nextflow installation
            self._validate_nextflow_installation()
            
            # Check disk space for both locations
            self._check_disk_space([self.db_location, self.conda_cache_dir])
            
            # Prepare directories
            self._prepare_directories()
            
            # Run installation
            self._run_nextflow_install()

class BacterialWorkflowValidator:
    @staticmethod
    def validate_threads(threads):
        """
        Validate thread count:
        - Must be a positive integer
        - Cannot exceed available system cores
        """
        try:
            threads = int(threads)
            max_cores = multiprocessing.cpu_count()
            
            if threads < 1:
                raise ValueError("Thread count must be a positive integer")
            
            if threads > max_cores:
                print(f"Warning: Requested threads ({threads}) exceeds available cores ({max_cores}). Using {max_cores} cores.")
                return max_cores
            
            return threads
        except ValueError:
            raise ValueError(f"Invalid thread count: {threads}. Must be a positive integer.")

    @staticmethod
    def validate_database_location(db_location):
        """
        Validate database location:
        - Must exist
        - Must be a directory
        """
        if not os.path.exists(db_location):
            raise ValueError(f"Database location does not exist: {db_location}")
        
        if not os.path.isdir(db_location):
            raise ValueError(f"Database location is not a directory: {db_location}")
        
        return db_location

    @staticmethod
    def validate_percentage_threshold(value, name):
        """
        Validate percentage thresholds:
        - Must be between 0 and 100
        """
        try:
            float_value = float(value)
            if float_value < 0 or float_value > 100:
                raise ValueError(f"{name} must be between 0 and 100")
            return float_value
        except ValueError:
            raise ValueError(f"Invalid {name}: {value}. Must be a number between 0 and 100.")

    @staticmethod
    def validate_ani_threshold(value):
        """
        Validate ANI threshold:
        - Must be between 0 and 1
        """
        try:
            float_value = float(value)
            if float_value < 0 or float_value > 1:
                raise ValueError("ANI threshold must be between 0 and 1")
            return float_value
        except ValueError:
            raise ValueError(f"Invalid ANI threshold: {value}. Must be a number between 0 and 1.")

    @staticmethod
    def validate_genome(genome_path):
        """
        Validate genome input:
        - Must be a file with .fa, .fasta, or .fna extension
        - Or a directory containing files with .fa, .fasta, or .fna extensions
        """
        if not os.path.exists(genome_path):
            raise ValueError(f"Genome path does not exist: {genome_path}")
        
        if os.path.isfile(genome_path):
            # Check file extension
            if not any(genome_path.endswith(ext) for ext in ['.fa', '.fasta', '.fna']):
                raise ValueError(f"Invalid genome file. Must end with .fa, .fasta, or .fna: {genome_path}")
            return genome_path
        
        if os.path.isdir(genome_path):
            # Check directory contains valid genome files
            genome_files = [
                f for f in os.listdir(genome_path) 
                if any(f.endswith(ext) for ext in ['.fa', '.fasta', '.fna'])
            ]
            
            if not genome_files:
                raise ValueError(f"No genome files found in directory. Files must end with .fa, .fasta, or .fna: {genome_path}")
            
            return genome_path
        
        raise ValueError(f"Invalid genome path: {genome_path}")
    
    @staticmethod
    def validate_directory(directory_path):
        """
        Validate directory:
        - Must exist
        - Must be a directory
        """
        if not os.path.exists(directory_path):
            raise ValueError(f"Directory does not exist: {directory_path}")
        
        if not os.path.isdir(directory_path):
            raise ValueError(f"Path is not a directory: {directory_path}")
        
        return directory_path
    
    @staticmethod
    def validate_output_directory(outdir):
        """
        Validate output directory:
        - If directory doesn't exist, create it
        - If it exists, print a warning
        """
        outdir = os.path.abspath(os.path.expanduser(outdir))
        
        if not os.path.exists(outdir):
            try:
                os.makedirs(outdir)
                print(f"Created output directory: {outdir}")
            except Exception as e:
                raise ValueError(f"Could not create output directory: {outdir}. Error: {e}")
        else:
            print(f"Warning: Using existing output directory: {outdir}")
        
        return outdir

class PhoragerBacterial:
    def __init__(self, 
             genome=None, 
             db_location=None, 
             conda_cache_dir=None,
             outdir=None,
             threads=None, 
             completeness_threshold=None, 
             contamination_threshold=None, 
             drep_ani_threshold=None,
             verbose=False,
             force=False):
    
        # Parse configuration
        config = NextflowConfigParser.parse_config()
        
        # Validate and set genome
        self.genome = BacterialWorkflowValidator.validate_genome(
            genome if genome is not None else config['genome']
        )
        
        # Validate and set database location
        self.db_location = BacterialWorkflowValidator.validate_database_location(
            db_location if db_location is not None else config['db_location']
        )
        
        # Validate and set conda cache directory
        self.conda_cache_dir = BacterialWorkflowValidator.validate_directory(
            conda_cache_dir if conda_cache_dir is not None else config['conda_cache_dir']
        )

        # Validate and set output directory
        self.outdir = BacterialWorkflowValidator.validate_output_directory(
            outdir if outdir is not None else config['outdir']
        )

        # Validate and set threads
        try:
            self.threads = BacterialWorkflowValidator.validate_threads(
                threads if threads is not None else config.get('threads', multiprocessing.cpu_count())
            )
        except KeyError:
            self.threads = BacterialWorkflowValidator.validate_threads(multiprocessing.cpu_count())
                
        # Validate and set completeness threshold
        self.completeness_threshold = BacterialWorkflowValidator.validate_percentage_threshold(
            completeness_threshold if completeness_threshold is not None else config['completeness_threshold'],
            'Completeness threshold'
        )
        
        # Validate and set contamination threshold
        self.contamination_threshold = BacterialWorkflowValidator.validate_percentage_threshold(
            contamination_threshold if contamination_threshold is not None else config['contamination_threshold'],
            'Contamination threshold'
        )
        
        # Validate and set dRep ANI threshold
        self.drep_ani_threshold = BacterialWorkflowValidator.validate_ani_threshold(
            drep_ani_threshold if drep_ani_threshold is not None else config['drep_ani_threshold']
        )
        
        # Set verbose and force flags
        self.verbose = verbose
        self.force = force
        
        # Setup logging
        self._setup_logging()

    def _setup_logging(self):
        """
        Configure logging with file and console output
        """
        # Create logs directory if it doesn't exist
        log_dir = Path('./phorager_logs')
        log_dir.mkdir(exist_ok=True)
        
        # Generate log filename with timestamp
        log_filename = log_dir / f"bacterial_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        
        # Configure logging
        logging.basicConfig(
            level=logging.DEBUG if self.verbose else logging.INFO,
            format='%(asctime)s - %(levelname)s: %(message)s',
            handlers=[
                logging.FileHandler(log_filename),
                logging.StreamHandler(sys.stdout)
            ]
        )
        self.logger = logging.getLogger(__name__)
        
        # Log the parameters being used
        self.logger.info(f"Genome: {self.genome}")
        self.logger.info(f"Database Location: {self.db_location}")
        self.logger.info(f"Threads: {self.threads}")
        self.logger.info(f"Completeness Threshold: {self.completeness_threshold}")
        self.logger.info(f"Contamination Threshold: {self.contamination_threshold}")
        self.logger.info(f"dRep ANI Threshold: {self.drep_ani_threshold}")
    
    def _run_nextflow_bacterial(self):
        """
        Run Nextflow bacterial workflow with comprehensive output handling
        """
        # Construct Nextflow command with validated parameters
        cmd = [
            'nextflow', 
            'run', 
            'main.nf', 
            '-profile', 'conda',
            '--workflow', 'bacterial',
            f'--genome', self.genome,
            f'--global_db_location', self.db_location,
            f'--outdir', self.outdir,
            f'--conda_cache_dir', self.conda_cache_dir,
            f'--threads', str(self.threads),
            f'--completeness_threshold', str(self.completeness_threshold),
            f'--contamination_threshold', str(self.contamination_threshold),
            f'--drep_ani_threshold', str(self.drep_ani_threshold)
        ]
        
        try:
            # Run installation with real-time output handling
            self.logger.info(f"Starting bacterial workflow...")
            
            # Use subprocess.Popen for real-time output
            process = subprocess.Popen(
                cmd, 
                stdout=subprocess.PIPE, 
                stderr=subprocess.STDOUT, 
                text=True,
                bufsize=1,
                universal_newlines=True
            )
            
            # Capture and log output in real-time
            output_lines = []
            while True:
                output = process.stdout.readline()
                if output == '' and process.poll() is not None:
                    break
                if output:
                    output = output.strip()
                    output_lines.append(output)
                    
                    # Log all output
                    self.logger.info(output)
                    
                    # Print to console if verbose
                    if self.verbose:
                        print(output)
            
            # Check return code
            if process.returncode != 0:
                raise subprocess.CalledProcessError(
                    process.returncode, 
                    cmd, 
                    '\n'.join(output_lines)
                )
            
            # Run cache and work directory cleanup
            try:
                # Nextflow clean command
                clean_cmd = ['nextflow', 'clean', '-f']
                subprocess.run(clean_cmd, check=True, capture_output=not self.verbose, text=True)
                
                # Remove work directory
                work_dir = os.path.join(self._resolve_project_dir(), 'work')
                if os.path.exists(work_dir):
                    shutil.rmtree(work_dir)
                    
                    # Log and print work directory removal
                    rm_message = f"Nextflow work directory removed successfully!"
                    self.logger.info(rm_message)
                    print(rm_message)
                
            except Exception as clean_error:
                # Log cleanup error
                error_message = f"Failed to clean directories: {clean_error}"
                self.logger.warning(error_message)
                print(error_message)
            
            # Log and print success message
            success_message = f"Bacterial workflow completed successfully!"
            self.logger.info(success_message)
            print(success_message)
        
        except subprocess.CalledProcessError as e:
            error_message = f"Bacterial workflow failed: {e}"
            self.logger.error(error_message)
            print(error_message)
            sys.exit(1)

    def _resolve_project_dir(self):
        """
        Resolve the project directory based on the current script location
        """
        return os.path.dirname(os.path.abspath(sys.argv[0]))
 
    def run(self):
        """
        Main workflow execution
        """
        self._run_nextflow_bacterial()

class ProphageWorkflowValidator:
    @staticmethod
    def validate_genome(genome_path):
        """
        Validate genome input
        - Must be a file or directory with .fa, .fasta, or .fna files
        """
        if not os.path.exists(genome_path):
            raise ValueError(f"Genome path does not exist: {genome_path}")
        
        if os.path.isfile(genome_path):
            if not any(genome_path.endswith(ext) for ext in ['.fa', '.fasta', '.fna']):
                raise ValueError(f"Invalid genome file. Must end with .fa, .fasta, or .fna: {genome_path}")
            return genome_path
        
        if os.path.isdir(genome_path):
            genome_files = [
                f for f in os.listdir(genome_path) 
                if any(f.endswith(ext) for ext in ['.fa', '.fasta', '.fna'])
            ]
            
            if not genome_files:
                raise ValueError(f"No genome files found in directory. Files must end with .fa, .fasta, or .fna: {genome_path}")
            
            return genome_path
        
        raise ValueError(f"Invalid genome path: {genome_path}")

    @staticmethod
    def validate_database_location(db_location):
        """
        Validate database location
        """
        if not os.path.exists(db_location):
            raise ValueError(f"Database location does not exist: {db_location}")
        
        if not os.path.isdir(db_location):
            raise ValueError(f"Database location is not a directory: {db_location}")
        
        return db_location

    @staticmethod
    def validate_threads(threads):
        """
        Validate thread count
        """
        try:
            threads = int(threads)
            max_cores = multiprocessing.cpu_count()
            
            if threads < 1:
                raise ValueError("Thread count must be a positive integer")
            
            if threads > max_cores:
                print(f"Warning: Requested threads ({threads}) exceeds available cores ({max_cores}). Using {max_cores} cores.")
                return max_cores
            
            return threads
        except ValueError:
            raise ValueError(f"Invalid thread count: {threads}. Must be a positive integer.")

class PhoragerProphage:
    def __init__(self, 
                 genome=None,
                 db_location=None,
                 conda_cache_dir=None,
                 outdir=None,
                 threads=None,
                 use_dereplicated_genomes=None,
                 skip_genomad=None,
                 skip_vibrant=None,
                 verbose=False,
                 force=False):
        
        # Parse configuration
        config = NextflowConfigParser.parse_config()
        
        # Validate and set genome
        self.genome = ProphageWorkflowValidator.validate_genome(
            genome if genome is not None else config['genome']
        )
        
        # Validate and set database location
        self.db_location = ProphageWorkflowValidator.validate_database_location(
            db_location if db_location is not None else config['db_location']
        )
        
        # Validate and set conda cache directory
        self.conda_cache_dir = ProphageWorkflowValidator.validate_database_location(
            conda_cache_dir if conda_cache_dir is not None else config['conda_cache_dir']
        )
        
        # Validate and set output directory
        self.outdir = ProphageWorkflowValidator.validate_database_location(
            outdir if outdir is not None else config['outdir']
        )
        
        # Validate and set threads
        self.threads = ProphageWorkflowValidator.validate_threads(
            threads if threads is not None else config['threads']
        )
        
        # Set boolean flags
        self.use_dereplicated_genomes = True if use_dereplicated_genomes else config['use_dereplicated_genomes']
        self.run_genomad = not (skip_genomad if skip_genomad is not None else False)
        self.run_vibrant = not (skip_vibrant if skip_vibrant is not None else False)
        
        self.verbose = verbose
        self.force = force
        
        # Setup logging
        self._setup_logging()
    
    def _setup_logging(self):
        """
        Configure logging with file and console output
        """
        log_dir = Path('./phorager_logs')
        log_dir.mkdir(exist_ok=True)
        
        log_filename = log_dir / f"prophage_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        
        logging.basicConfig(
            level=logging.DEBUG if self.verbose else logging.INFO,
            format='%(asctime)s - %(levelname)s: %(message)s',
            handlers=[
                logging.FileHandler(log_filename),
                logging.StreamHandler(sys.stdout)
            ]
        )
        self.logger = logging.getLogger(__name__)
        
        # Log parameters
        self.logger.info(f"Genome: {self.genome}")
        self.logger.info(f"Database Location: {self.db_location}")
        self.logger.info(f"Threads: {self.threads}")
        self.logger.info(f"Use Dereplicated Genomes: {self.use_dereplicated_genomes}")
        self.logger.info(f"Run geNomad: {self.run_genomad}")
        self.logger.info(f"Run VIBRANT: {self.run_vibrant}")
    
    def _run_nextflow_prophage(self):
        """
        Run Nextflow prophage workflow
        """
        cmd = [
            'nextflow', 
            'run', 
            'main.nf', 
            '-profile', 'conda',
            '--workflow', 'prophage',
            f'--genome', self.genome,
            f'--global_db_location', self.db_location,
            f'--conda_cache_dir', self.conda_cache_dir,
            f'--outdir', self.outdir,
            f'--threads', str(self.threads),
            f'--use_dereplicated_genomes', str(self.use_dereplicated_genomes),
            f'--run_genomad', str(self.run_genomad),
            f'--run_vibrant', str(self.run_vibrant)
        ]
        
        try:
            self.logger.info("Starting prophage workflow...")
            
            process = subprocess.Popen(
                cmd, 
                stdout=subprocess.PIPE, 
                stderr=subprocess.STDOUT, 
                text=True,
                bufsize=1,
                universal_newlines=True
            )
            
            output_lines = []
            while True:
                output = process.stdout.readline()
                if output == '' and process.poll() is not None:
                    break
                if output:
                    output = output.strip()
                    output_lines.append(output)
                    
                    self.logger.info(output)
                    
                    if self.verbose:
                        print(output)
            
            if process.returncode != 0:
                raise subprocess.CalledProcessError(
                    process.returncode, 
                    cmd, 
                    '\n'.join(output_lines)
                )
            
            # Cleanup
            clean_cmd = ['nextflow', 'clean', '-f']
            subprocess.run(clean_cmd, check=True, capture_output=not self.verbose, text=True)
            
            work_dir = os.path.join(self._resolve_project_dir(), 'work')
            if os.path.exists(work_dir):
                shutil.rmtree(work_dir)
            
            success_message = "Prophage workflow completed successfully!"
            self.logger.info(success_message)
            print(success_message)
        
        except subprocess.CalledProcessError as e:
            error_message = f"Prophage workflow failed: {e}"
            self.logger.error(error_message)
            print(error_message)
            sys.exit(1)
    
    def _resolve_project_dir(self):
        """
        Resolve the project directory
        """
        return os.path.dirname(os.path.abspath(sys.argv[0]))
    
    def run(self):
        """
        Main workflow execution
        """
        self._run_nextflow_prophage()

def main():    
    # Create the top-level parser
    parser = argparse.ArgumentParser(description='Phorager: Nextflow Pipeline Database Installer and Workflow Runner')
    
    # Create subparsers
    subparsers = parser.add_subparsers(dest='command', help='Subcommands')
    
    # Install subcommand
    install_parser = subparsers.add_parser('install', help='Install databases')
    install_parser.add_argument(
        '--db-location', 
        help='Custom database installation location'
    )
    install_parser.add_argument(
        '--conda-cache', 
        help='Custom conda cache directory'
    )
    install_parser.add_argument(
        '--force', 
        action='store_true', 
        help='Force reinstall all databases'
    )
    install_parser.add_argument(
        '--verbose', 
        action='store_true', 
        help='Enable verbose logging'
    )
    
    # Bacterial subcommand
    bacterial_parser = subparsers.add_parser('bacterial', help='Run bacterial workflow')
    bacterial_parser.add_argument('--genome', help='Path to genome file or directory')
    bacterial_parser.add_argument('--db-location', help='Database location')
    bacterial_parser.add_argument('--outdir', help='Output directory')
    bacterial_parser.add_argument('--conda-cache', help='Conda cache directory location')
    bacterial_parser.add_argument('--threads', type=int, help='Number of threads')
    bacterial_parser.add_argument('--completeness-threshold', type=float, help='Completeness threshold')
    bacterial_parser.add_argument('--contamination-threshold', type=float, help='Contamination threshold')
    bacterial_parser.add_argument('--drep-ani-threshold', type=float, help='dRep ANI threshold')
    bacterial_parser.add_argument('--verbose', action='store_true', help='Enable verbose output')
    bacterial_parser.add_argument('--force', action='store_true', help='Force overwrite')
    
    # Prophage detection parser
    prophage_parser = subparsers.add_parser('prophage', help='Run prophage workflow')
    prophage_parser.add_argument('--genome', help='Path to genome file or directory')
    prophage_parser.add_argument('--db-location', help='Database location')
    prophage_parser.add_argument('--conda-cache', help='Conda cache directory location')
    prophage_parser.add_argument('--outdir', help='Output directory')
    prophage_parser.add_argument('--threads', type=int, help='Number of threads')
    prophage_parser.add_argument('--use-dereplicated-genomes', action='store_true', help='Use dereplicated genomes')
    prophage_parser.add_argument('--skip-genomad', action='store_true', help='Skip geNomad analysis')
    prophage_parser.add_argument('--skip-vibrant', action='store_true', help='Skip VIBRANT analysis')
    prophage_parser.add_argument('--verbose', action='store_true', help='Enable verbose output')
    prophage_parser.add_argument('--force', action='store_true', help='Force overwrite')

    # Parse arguments
    args = parser.parse_args()
    
    # Check if a subcommand was provided
    if args.command is None:
        parser.print_help()
        sys.exit(1)
    
    # Run install workflow
    if args.command == 'install':
        installer = PhoragerInstaller(
            db_location=args.db_location,
            conda_cache_dir=args.conda_cache,
            force_reinstall=args.force, 
            verbose=args.verbose
        )
        installer.run()
    
    # Run bacterial workflow
    elif args.command == 'bacterial':
        try:
            workflow = PhoragerBacterial(
                genome=args.genome,
                db_location=args.db_location,
                conda_cache_dir=args.conda_cache,
                outdir=args.outdir,
                threads=args.threads,
                completeness_threshold=args.completeness_threshold,
                contamination_threshold=args.contamination_threshold,
                drep_ani_threshold=args.drep_ani_threshold,
                verbose=args.verbose,
                force=args.force
            )
            workflow.run()
        except Exception as e:
            print(f"Error: {e}")
            sys.exit(1)
    
    # Run Propgae workflow
    elif args.command == 'prophage':
        try:
            workflow = PhoragerProphage(
                genome=args.genome,
                db_location=args.db_location,
                conda_cache_dir=args.conda_cache,
                outdir=args.outdir,
                threads=args.threads,
                use_dereplicated_genomes=args.use_dereplicated_genomes,
                skip_genomad=args.skip_genomad,
                skip_vibrant=args.skip_vibrant,
                verbose=args.verbose,
                force=args.force
            )
            workflow.run()
        except Exception as e:
            print(f"Error: {e}")
            sys.exit(1)

if __name__ == '__main__':
    main()
